# Embeddings

## Word Vectors and the Universal Sentence Encoder

- 📝 [Understanding word vectors](https://gist.github.com/aparrish/2f562e3737544cf29aaf1af30362f469)
- 🚂 [What is word2vec](https://youtu.be/LSS_bos_TPI), 🚂 [Color Vectors](https://youtu.be/mI23bDF0VRI)
- 📚 [2013 paper Efficient Estimation of Word Representations in Vector Space](https://arxiv.org/abs/1301.3781)
- 🔢 [GloVe: Global Vectors for Word Representation](https://nlp.stanford.edu/projects/glove/)
- 📚 [2018 Universal Sentence Encoder paper](https://arxiv.org/abs/1803.11175)

## Embeddings

- 🎥 [What are Word Embeddings?](https://www.youtube.com/watch?v=wgfSDrqYMJ4) from IBM
- 🎨 [Embeddings Projector](https://projector.tensorflow.org/) and [Visualizing High Dimensional Space](https://youtu.be/wvsE8jm1GzE), [Atlas](https://atlas.nomic.ai/)
- 📝 [Embeddings tutorial](https://docs.cohere.com/docs/text-embeddings) from Cohere
- 📚 [What are embeddings?](https://vickiboykis.com/what_are_embeddings/) by Vicki Boykis
- 📚 [Embeddings: What they are and why they matter](https://simonwillison.net/2023/Oct/23/embeddings/)

## Semantic Search and "Similarity"

- 📚 [What is Semantic Search?](https://cohere.com/llmu/what-is-semantic-search)
- 🎥 [Cosine Similarity](https://youtu.be/e9U0QAFbfLI) from StatQuest

## Code Examples

- 💻 [Comparison Matrix](https://editor.p5js.org/ml_4_cc/sketches/QT7LqyzoE)
- 💻 [Semantic Search Text](https://editor.p5js.org/ml_4_cc/sketches/MhXel085k)
- 💻 [Zero Shot Image Classification](https://editor.p5js.org/ml_4_cc/sketches/DbNwvgglU) - uses CLIP multi-modal model
- 💻 [Zero Shot Object Detection](https://editor.p5js.org/ml_4_cc/sketches/Pwp6TtHGT)
- 💻 [Simple Text Semantic Search with 10 images](https://editor.p5js.org/ml_4_cc/sketches/s_u_1-udh)
- 💻 [Simple Image Semantic Search with 10 images](https://editor.p5js.org/ml_4_cc/sketches/CWE6Ox_jd)
- 💻 [Semantic Search with 25k images - deployed](https://sem-search-tfjs.netlify.app/), [Semantic Search Image - Github Repo](https://github.com/shiffman/Semantic-Search-Images)

## Clustering with UMAP dimensionality reduction

- [Sentence Embeddings with transformers.js and UMAP](https://thecodingtrain.com/tracks/livestreams/livestreams/sentence-embeddings/clustering-sentence-embeddings)
- [Understanding UMAP](https://pair-code.github.io/understanding-umap/)
- [umap-js](https://github.com/PAIR-code/umap-js)
- UMAP p5.js examples
  - [Simple clustering 3D colors -> 2D](https://editor.p5js.org/ml_4_cc/sketches/ggF_2InLiL)
  - [Simple clustering random data, adjusting umap parameters](https://editor.p5js.org/ml_4_cc/sketches/EENH_ADmE)
  - [Animated UMAP process + Clustering sentence embeddings from a database!](https://editor.p5js.org/a2zitp/sketches/p63QTp0Sd)

## Assignment

The goal of this week's assignment is to make forward progress on your work, and the assignment is intended to be highly flexible and exploratory. Consider the following three options:

1. Continue exploring [any transformer.js compatible model](https://huggingface.co/models?library=transformers.js&sort=trending) with p5.js. Compare your experience working with transformers.js to ml5.js or TensorFlow.js. Document any errors or challenges you encounter.
2. Focus specifically on embeddings with transformers.js (you could also revisit embeddings with TensorFlow.js or other ML platforms). Build upon the semantic search or zero-shot classification/object detection examples provided. If you're interested, you could also experiment with visualizing embeddings through clustering, using the provided examples and resources, even though we didn't get to cover clustering in class.
3. If you already have an idea for your final project or prefer to continue developing a previous assignment or experiment, this is also encouraged.

Please post your work and documentation to the [Assignment 6 Wiki page](https://github.com/shiffman/ML-for-Creative-Coding/wiki/Assignment-6). Have fun exploring!
