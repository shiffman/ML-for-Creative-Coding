# Fine-Tuning

## Resources

- [What is fine-tuning](https://www.ibm.com/topics/fine-tuning)
- [What is Low-Rank Adaptation (LoRA) | Explained by the Inventor](https://www.youtube.com/watch?v=DhRoTONcyZE)
- [LoRA: Low-Rank Adaptation of Large Language Models](https://arxiv.org/pdf/2106.09685)
- [Parameter-Efficient LLM Finetuning With Low-Rank Adaptation (LoRA)](https://sebastianraschka.com/blog/2023/llm-finetuning-lora.html)
- [Fine-tune a pretrained model](https://huggingface.co/docs/transformers/en/training) by Hugging Face
- [PEFT: Parameter-Efficient Fine-Tuning Methods for LLMs](https://huggingface.co/blog/samuellimabraz/peft-methods)
- [OpenAI's Reinforcement Fine-Tuning Research Program](https://openai.com/form/rft-research-program/)

## Tools

- [Fine-tune FLUX.1 with your own images](https://replicate.com/blog/fine-tune-flux) on Replicate
- [You can now fine-tune open-source video models](https://replicate.com/blog/fine-tune-video) on Replicate
- [Example Code for Prepping Dataset](https://github.com/Programming-from-A-to-Z/Data-for-Fine-Tuning)
- [Fine-Tuning Guide](https://gist.github.com/shiffman/72b4688f6885a08c27041bb352134579)
- [Fine-Tuning Guide for NYU HPC](https://gist.github.com/shiffman/b960a575988245313a99df47030cedfc)
- [OpenAI API Fine Tuning](https://platform.openai.com/docs/guides/fine-tuning)
- [AutoTrain on Hugging Face](https://huggingface.co/autotrain)
- [Gemma model fine-tuning](https://ai.google.dev/gemma/docs/tune)
- [Full Stable Diffusion SD & XL Fine Tuning Tutorial With OneTrainer](https://www.youtube.com/watch?v=0t5l6CP9eBg)
